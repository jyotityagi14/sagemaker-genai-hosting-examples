# This is official repository for SageMaker AI hosting workshop

1. Lab 1
2. Lab 2: deploy state of the art LLM (Llama 3/DeepSeek/Qwen) [lab 2](./lab2)
3. Lab 3: deploy multiple state-of-the-art LLMs on a single endpoint with Scale-to-Zero [lab 3](./lab3)
4. Lab 4:
5. Lab 5: deploy base model with multiple LoRA adapters (using LMI and Llama 3.1 8B Instruct model)[lab 5](./lab5)



   
